[
  {
    "id": "DATA TEMPLATE",
    "title": "",
    "abstract": "",
    "bibtex": "",
    "acmref": ""
  },
  {
    "id": 22,
    "title": "Mobiot: Augmenting Everyday Objects into Moving IoT Devices Using 3D Printed Attachments Generated by Demonstration",
    "abstract": "Recent advancements in personal fabrication have brought novices closer to a reality, where they can automate routine tasks with mobilized everyday objects. However, the overall process remains challenging- from capturing design requirements and motion planning to authoring them to creating 3D models of mechanical parts to programming electronics, as it demands expertise. We introduce Mobiot, an end-user toolkit to help non-experts capture the design and motion requirements of legacy objects by demonstration. It then automatically generates 3D printable attachments, programs to operate assembled modules, a list of off-the-shelf electronics, and assembly tutorials. The authoring feature further assists users to fine-tune as well as to reuse existing motion libraries and 3D printed mechanisms to adapt to other real-world objects with different motions. We validate Mobiot through application examples with 8 everyday objects with various motions applied, and through technical evaluation to measure the accuracy of motion reconstruction.",
    "bibtex": "",
    "acmref": ""
  },
  {
    "id": 21,
    "title": "Roman: Making Everyday Objects Robotically Manipulable with 3D-Printable Add-on Mechanisms",
    "abstract": "One important vision of robotics is to provide physical assistance by manipulating diferent everyday objects, e.g., hand tools, kitchen utensils. However, many objects designed for dexterous hand-control are not easily manipulable by a single robotic arm with a generic parallel gripper. Complementary to existing research on develop- ing grippers and control algorithms, we present Roman, a suite of hardware design and software tool support for robotic engineers to create 3D printable mechanisms attached to everyday handheld ob- jects, making them easier to be manipulated by conventional robotic arms. The Roman hardware comes with a versatile magnetic gripper that can snap on/of handheld objects and drive add-on mechanisms to perform tasks. Roman also provides software support to register and author control programs. To validate our approach, we designed and fabricated Roman mechanisms for 14 everyday objects/tasks presented within a design space and conducted expert interviews with robotic engineers indicating that Roman serves as a practical alternative for enabling robotic manipulation of everyday objects.",
    "bibtex": "",
    "acmref": ""
  },
  {
    "id": 20,
    "title": "Fab4D : An Accessible Hybrid Approach for Programmable Shaping and Shape Changing Artifacts",
    "abstract": "Hand-weaving is a beloved craft in history, holding promise for many opportunities in making from flat sheet fabrics to smart textiles. To afford new weaving experiences, we explore how 3D printed custom weaving tools interplay with different materiality, augmenting the design space of weaving. We propose novel weaving techniques enabled by 3D printed custom tools: (1) water-soluble draft to synchronize design intention and practice, (2) flexible warps to guide complex patterns and to shape resulting object, and (3) rigid global geometry for woven artifacts in 3D. EscapeLoom as a computational design tool enables users to employ various parameters in their computational design, and showcases many creative possibilities that move away from the traditional definition of a loom to dive into what more it can be.",
    "bibtex": "@inproceedings{10.1145/3490149.3505574,\nauthor = {Deshpande, Himani and Zheng, Clement and Starrett, Courtney and Seo, Jinsil Hwaryoung and Kim, Jeeeun},\ntitle = {Fab4D : An Accessible Hybrid Approach for Programmable Shaping and Shape Changing Artifacts},\nyear = {2022},\nisbn = {9781450391474},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3490149.3505574},\ndoi = {10.1145/3490149.3505574},\nabstract = { 4D printing is a new technique for human-computer interaction to create self bending and actuating interfaces, leveraging the properties of 3D printed materials for shape change over time, triggered by external factors such as heat. Given the ubiquity of low-cost 3D printers, we see an opportunity to translate 4D printing from the research lab into makerspaces and educational settings. In this work, we explore low cost 4D printing with shape memory polymers and desktop 3D printers, tackling hybrid fabrication approach to lower the barrier for non-experts. We see heat as one promising way of creating shape changing behaviors using common triggering methods such as oven, hair dryer, hot water. We present the initial design space for hybrid fabrication with factors that help characterize and control bending behaviors, showcasing potential design contexts with 4D printed applications. },\nbooktitle = {Sixteenth International Conference on Tangible, Embedded, and Embodied Interaction},\narticleno = {70},\nnumpages = {7},\nkeywords = {FDM, makerspaces, craft, 4D printing},\nlocation = {Daejeon, Republic of Korea},\nseries = {TEI '22}\n}",
    "acmref": "Himani Deshpande, Clement Zheng, Courtney Starrett, Jinsil Hwaryoung Seo, and Jeeeun Kim. 2022. Fab4D : An Accessible Hybrid Approach for Programmable Shaping and Shape Changing Artifacts. In <i>Sixteenth International Conference on Tangible, Embedded, and Embodied Interaction</i> (<i>TEI '22</i>). Association for Computing Machinery, New York, NY, USA, Article 70, 1–7. DOI:https://doi.org/10.1145/3490149.3505574"
  },
  {
    "id": 19,
    "title": "Multi-ttach: Techniques to Enhance Multi-material Attachments in Low-cost FDM 3D Printing",
    "abstract": "Recent advances in low-cost FDM 3D printing and a range of commercially available materials have enabled integrating different properties into a single object such as flexibility and conductivity, assisting fabrication of a wide variety of interactive devices through multi-material printing. Mechanically different materials such as rigid and flexible filament, however, display issues when adhering to each other making the object vulnerable to coming apart. In this work, we propose Multi-ttach, a low-cost technique to increase the adhesion between different materials utilizing various 3D printing parameters with three specialized geometric structures : (1) bead and (2) lattice structures that interlock layers in vertical material arrangement, and (3) stitching in horizontal material arrangement. We approach this by modifying the geometry of the interface layer at the G-code level and using processing parameters. We validate the result through mechanical testing using off-the-shelf materials and desktop printers and demonstrate the applicability through a range of existing applications that tackle the benefit of multi-material FDM 3D printing.",
    "bibtex": "@inproceedings{kwon2021multi,\n  title={Multi-ttach: Techniques to Enhance Multi-material Attachments in Low-cost FDM 3D Printing},\n  author={Kwon, Nahyun and Deshpande, Himani and Hasan, Md Kamrul and Darnal, Aryabhat and Kim, Jeeeun},\n  booktitle={Symposium on Computational Fabrication},\n  pages={1--16},\n  year={2021}\n}",
    "acmref": "Nahyun Kwon, Himani Deshpande, Md Kamrul Hasan, Aryabhat Darnal, and Jeeeun Kim. 2021. Multi-ttach: Techniques to Enhance Multi-material Attachments in Low-cost FDM 3D Printing. In Symposium on Computational Fabrication (SCF '21). Association for Computing Machinery, New York, NY, USA, Article 4, 1–16. DOI:https://doi.org/10.1145/3485114.3485116"
  },
  {
    "id": 18,
    "title": "3D4ALL: Toward an Inclusive Pipeline to Classify 3D Contents",
    "abstract": "Algorithmic content moderation manages an explosive number of user-created content shared online everyday. Despite a massive number of 3D designs that are free to be downloaded, shared, and 3D printed by the users, detecting sensitivity with transparency and fairness has been controversial. Although sensitive 3D content might have a greater impact than other media due to its possible reproducibility and replicability without restriction, prevailed unawareness resulted in proliferation of sensitive 3D models online and a lack of discussion on transparent and fair 3D content moderation. As the 3D content exists as a document on the web mainly consisting of text and images, we first study the existing algorithmic efforts based on text and images and the prior endeavors to encompass transparency and fairness in moderation, which can also be useful in a 3D printing domain. At the same time, we identify 3D specific features that should be addressed to advance a 3D specialized algorithmic moderation. As a potential solution, we suggest a human-in-the-loop pipeline using augmented learning, powered by various stakeholders with different backgrounds and perspectives in understanding the content. Our pipeline aims to minimize personal biases by enabling diverse stakeholders to be vocal in reflecting various factors to interpret the content. We add our initial proposal for redesigning metadata of open 3D repositories, to invoke users' responsible actions of being granted consent from the subject upon sharing contents for free in the public spaces.",
    "bibtex": "@article{kwon20213d4all,\n  title={3D4ALL: Toward an Inclusive Pipeline to Classify 3D Contents},\n  author={Kwon, Nahyun and Liang, Chen and Kim, Jeeeun},\n  journal={arXiv preprint arXiv:2102.12606},\n  year={2021}\n}",
    "acmref": ""
  },
  {
    "id": 17,
    "title": "EscapeLoom: Fabricating New Affordances for Hand Weaving",
    "abstract": "Hand-weaving is a beloved craft in history, holding promise for many opportunities in making from flat sheet fabrics to smart textiles. To afford new weaving experiences, we explore how 3D printed custom weaving tools interplay with different materiality, augmenting the design space of weaving. We propose novel weaving techniques enabled by 3D printed custom tools: (1) water-soluble draft to synchronize design intention and practice, (2) flexible warps to guide complex patterns and to shape resulting object, and (3) rigid global geometry for woven artifacts in 3D. EscapeLoom as a computational design tool enables users to employ various parameters in their computational design, and showcases many creative possibilities that move away from the traditional definition of a loom to dive into what more it can be.",
    "bibtex": "@inproceedings{10.1145/3411764.3445600,\nauthor = {Deshpande, Himani and Takahashi, Haruki and Kim, Jeeeun},\ntitle = {EscapeLoom: Fabricating New Affordances for Hand Weaving},\nyear = {2021},\nisbn = {9781450380966},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3411764.3445600},\ndoi = {10.1145/3411764.3445600},\nabstract = {Hand-weaving is a beloved craft in history, holding promise for many opportunities in making from flat sheet fabrics to smart textiles. To afford new weaving experiences, we explore how 3D printed custom weaving tools interplay with different materiality, augmenting the design space of weaving. We propose novel weaving techniques enabled by 3D printed custom tools: (1) water-soluble draft to synchronize design intention and practice, (2) flexible warps to guide complex patterns and to shape resulting object, and (3) rigid global geometry for woven artifacts in 3D. EscapeLoom as a computational design tool enables users to employ various parameters in their computational design, and showcases many creative possibilities that move away from the traditional definition of a loom to dive into what more it can be. },\nbooktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},\narticleno = {630},\nnumpages = {13},\nkeywords = {digital fabrication, weaving},\nlocation = {Yokohama, Japan},\nseries = {CHI '21}\n}",
    "acmref": "Himani Deshpande, Haruki Takahashi, and Jeeeun Kim. 2021. EscapeLoom: Fabricating New Affordances for Hand Weaving. In <i>Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems</i> (<i>CHI '21</i>). Association for Computing Machinery, New York, NY, USA, Article 630, 1–13. DOI:https://doi.org/10.1145/3411764.3445600"
  },
  {
    "id": 16,
    "title": "HowDIY: Towards Meta-Design Tools to Support Anyone to 3D Print Anywhere",
    "abstract": "",
    "bibtex": "",
    "acmref": ""
  },
  {
    "id": 15,
    "title": "OmniSoft: A Design Tool for Soft Objects by Example",
    "abstract": "",
    "bibtex": "",
    "acmref": ""
  },
  {
    "id": 14,
    "title": "Programmable Filament: Printed Filaments for Multi-material 3D Printing",
    "abstract": "From full-color objects to functional capacitive artifacts, 3D printing multi-materials became essential to broaden the application areas of digital fabrication. We present Programmable Filament, a novel technique that enables multi-material printing using a commodity FDM 3D printer, requiring no hardware upgrades. Our technique builds upon an existing printing technique in which multiple filament segments are printed and spliced into a single threaded filament. We propose an end-toend pipeline for 3D printing an object in multi-materials, with an introduction of the design systems for end-users. Optimized for low-cost, single-nozzle FDM 3D printers, the system is built upon our computational analysis and experiments to enhance its validity over various printers and materials to design and produce a programmable filament. Finally, we discuss application examples and speculate the future with its potential, such as custom filament manufacturing on-demand.",
    "bibtex": "@inproceedings{10.1145/3379337.3415863,\nauthor = {Takahashi, Haruki and Punpongsanon, Parinya and Kim, Jeeeun},\ntitle = {Programmable Filament: Printed Filaments for Multi-Material 3D Printing},\nyear = {2020},\nisbn = {9781450375146},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3379337.3415863},\ndoi = {10.1145/3379337.3415863},\nabstract = {From full-color objects to functional capacitive artifacts, 3D printing multi-materials became essential to broaden the application areas of digital fabrication. We present Programmable Filament, a novel technique that enables multi-material printing using a commodity FDM 3D printer, requiring no hardware upgrades. Our technique builds upon an existing printing technique in which multiple filament segments are printed and spliced into a single threaded filament. We propose an end-to-end pipeline for 3D printing an object in multi-materials, with an introduction of the design systems for end-users. Optimized for low-cost, single-nozzle FDM 3D printers, the system is built upon our computational analysis and experiments to enhance its validity over various printers and materials to design and produce a programmable filament. Finally, we discuss application examples and speculate the future with its potential, such as custom filament manufacturing on-demand.},\nbooktitle = {Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology},\npages = {1209–1221},\nnumpages = {13},\nkeywords = {programmable matters, multiple materials, fused deposition modeling, 3d printing},\nlocation = {Virtual Event, USA},\nseries = {UIST '20}\n}",
    "acmref": "Haruki Takahashi, Parinya Punpongsanon, and Jeeeun Kim. 2020. Programmable Filament: Printed Filaments for Multi-material 3D Printing. In <i>Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology</i> (<i>UIST '20</i>). Association for Computing Machinery, New York, NY, USA, 1209–1221. DOI:https://doi.org/10.1145/3379337.3415863"
  },
  {
    "id": 13,
    "title": "Romeo: A Design Tool for Embedding Transformable Parts in 3D Models to Robotically Augment Default Functionality",
    "abstract": "Reconfiguring shapes of objects enables transforming existing passive objects with robotic functionalities, e.g., a transformable coffee cup holder can be attached to a chair’s armrest, a piggybank can reach out an arm to ’steal’ coins. Despite the advance in end-user 3D design and fabrication, it remains challenging for non-experts to create such ‘transformables’ using existing tools due to the requirement of specific engineering knowledge such as mechanisms and robotic design. We present Romeo—a design tool for creating transformables embedded into a 3D model to robotically augment the object’s default functionalities. Romeo allows users to express at a high level, (1) which part of the object to be transformed, (2) how it moves following motion points in space, and (3) the corresponding action to be taken. Romeo then automatically generates a robotic arm embedded in the transformable part ready for fabrication. We validated Romeo with a design session where 8 participants design and create custom transformables using 3D objects of their own choice.",
    "bibtex": "@inbook{10.1145/3419249.3420068,\nauthor = {Berman, Alexander and Quek, Francis and Woodward, Robert and Okundaye, Osazuwa and Kim, Jeeeun},\ntitle = {“Anyone Can Print”: Supporting Collaborations with 3D Printing Services to Empower Broader Participation in Personal Fabrication},\nyear = {2020},\nisbn = {9781450375795},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3419249.3420068},\nabstract = { Broader participation in 3D printing may be facilitated through printing services that insulate clients from the costs and detailed technical knowledge necessary to operate and maintain printers. However, newcomers to 3D printing encounter barriers and challenges even before gaining access to printing facilities. This paper explores the challenges and barriers newcomers encounter when identifying printing opportunities and when learning how to specify 3D printing ideas through observations of stakeholders (n=20) in two university 3D printing shops, and through a focused lab study investigating how to introduce newcomers individually to 3D printing (n=21). We adopt Olsons and Olson’s framework for remote collaborations, proposed in “Distance Matters”, to analyze the sociotechnical requirements for initiating collaborations with 3D printing services. We found that newcomers often require prior guidance towards 3D printing procedures and websites before establishing what to print in collaboration with 3D printing services. Finally, we discuss how future printing processes and computational systems may empower a future where Anyone Can Print.},\nbooktitle = {Proceedings of the 11th Nordic Conference on Human-Computer Interaction: Shaping Experiences, Shaping Society},\narticleno = {1},\nnumpages = {13}\n}",
    "acmref": "Jiahao Li, Meilin Cui, Jeeeun Kim, and Xiang 'Anthony' Chen. 2020. Romeo: A Design Tool for Embedding Transformable Parts in 3D Models to Robotically Augment Default Functionalities. In <i>Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology</i> (<i>UIST '20</i>). Association for Computing Machinery, New York, NY, USA, 897–911. DOI:https://doi.org/10.1145/3379337.3415826"
  },
  {
    "id": 12,
    "title": "Anyone Can Print\": Supporting Collaborations with 3D Printing Services to Empower Broader Participation in Personal Fabrication",
    "abstract": "Broader participation in 3D printing may be facilitated through printing services that insulate clients from the costs and detailed technical knowledge necessary to operate and maintain printers. However, newcomers to 3D printing encounter barriers and challenges even before gaining access to printing facilities. This paper explores the challenges and barriers newcomers encounter when identifying printing opportunities and when learning how to specify 3D printing ideas through observations of stakeholders (n=20) in two university 3D printing shops, and through a focused lab study investigating how to introduce newcomers individually to 3D printing (n=21). We adopt Olsons and Olson’s framework for remote collaborations, proposed in “Distance Matters”, to analyze the sociotechnical requirements for initiating collaborations with 3D printing services. We found that newcomers often require prior guidance towards 3D printing procedures and websites before establishing what to print in collaboration with 3D printing services. Finally, we discuss how future printing processes and computational systems may empower a future where Anyone Can Print.",
    "bibtex": "@inbook{10.1145/3419249.3420068,\nauthor = {Berman, Alexander and Quek, Francis and Woodward, Robert and Okundaye, Osazuwa and Kim, Jeeeun},\ntitle = {“Anyone Can Print”: Supporting Collaborations with 3D Printing Services to Empower Broader Participation in Personal Fabrication},\nyear = {2020},\nisbn = {9781450375795},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3419249.3420068},\nabstract = { Broader participation in 3D printing may be facilitated through printing services that insulate clients from the costs and detailed technical knowledge necessary to operate and maintain printers. However, newcomers to 3D printing encounter barriers and challenges even before gaining access to printing facilities. This paper explores the challenges and barriers newcomers encounter when identifying printing opportunities and when learning how to specify 3D printing ideas through observations of stakeholders (n=20) in two university 3D printing shops, and through a focused lab study investigating how to introduce newcomers individually to 3D printing (n=21). We adopt Olsons and Olson’s framework for remote collaborations, proposed in “Distance Matters”, to analyze the sociotechnical requirements for initiating collaborations with 3D printing services. We found that newcomers often require prior guidance towards 3D printing procedures and websites before establishing what to print in collaboration with 3D printing services. Finally, we discuss how future printing processes and computational systems may empower a future where Anyone Can Print.},\nbooktitle = {Proceedings of the 11th Nordic Conference on Human-Computer Interaction: Shaping Experiences, Shaping Society},\narticleno = {1},\nnumpages = {13}\n}",
    "acmref": "Alexander Berman, Francis Quek, Robert Woodward, Osazuwa Okundaye, and Jeeeun Kim. 2020. “Anyone Can Print”: Supporting Collaborations with 3D Printing Services to Empower Broader Participation in Personal Fabrication. <i>Proceedings of the 11th Nordic Conference on Human-Computer Interaction: Shaping Experiences, Shaping Society</i>. Association for Computing Machinery, New York, NY, USA, Article 1, 1–13. DOI:https://doi.org/10.1145/3419249.3420068"
  },
  {
    "id": 11,
    "title": "3D Printed Fabric: Techniques for Design and 3D Weaving Programmable Textiles",
    "abstract": "We present a technique for fabricating soft and flexible textiles using a consumer grade fused deposition modeling (FDM) 3D printer. By controlling the movement of the print header, the FDM alternately weaves the stringing fibers across a row of pillars. Owing to the structure of the fibers, which supports and strengthens the pillars from each side, a 3D printer can print a thin sheet of fabric in an upright position while the fibers are being woven. In addition, this technique enables users to employ materials with various colors and/or properties when designing a pattern, and to prototype an interactive object using a variety of off-the-shelf materials such as a conductive filament. We also describe a technique for weaving textiles and introduce a list of parameters that enable users to design their own textile variations. Finally, we demonstrate examples showing the feasibility of our approach as well as numerous applications integrating printed textiles in a custom object design.",
    "bibtex": "@inproceedings{10.1145/3332165.3347896,\nauthor = {Takahashi, Haruki and Kim, Jeeeun},\ntitle = {3D Printed Fabric: Techniques for Design and 3D Weaving Programmable Textiles},\nyear = {2019},\nisbn = {9781450368162},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3332165.3347896},\ndoi = {10.1145/3332165.3347896},\nabstract = {We present a technique for fabricating soft and flexible textiles using a consumer grade fused deposition modeling (FDM) 3D printer. By controlling the movement of the print header, the FDM alternately weaves the stringing fibers across a row of pillars. Owing to the structure of the fibers, which supports and strengthens the pillars from each side, a 3D printer can print a thin sheet of fabric in an upright position while the fibers are being woven. In addition, this technique enables users to employ materials with various colors and/or properties when designing a pattern, and to prototype an interactive object using a variety of off-the-shelf materials such as a conductive filament. We also describe a technique for weaving textiles and introduce a list of parameters that enable users to design their own textile variations. Finally, we demonstrate examples showing the feasibility of our approach as well as numerous applications integrating printed textiles in a custom object design.},\nbooktitle = {Proceedings of the 32nd Annual ACM Symposium on User Interface Software and Technology},\npages = {43–51},\nnumpages = {9},\nkeywords = {printing technique, 3d printed textile, digital fabrication, fused deposition modeling, 3d printing},\nlocation = {New Orleans, LA, USA},\nseries = {UIST '19}\n}",
    "acmref": "Haruki Takahashi and Jeeeun Kim. 2019. 3D Printed Fabric: Techniques for Design and 3D Weaving Programmable Textiles. In <i>Proceedings of the 32nd Annual ACM Symposium on User Interface Software and Technology</i> (<i>UIST '19</i>). Association for Computing Machinery, New York, NY, USA, 43–51. DOI:https://doi.org/10.1145/3332165.3347896"
  },
  {
    "id": 10,
    "title": "Robiot: A Design Tool for Actuating Everyday Objects with Automatically generated 3D Printable Mechanisms",
    "abstract": "Users can now easily communicate digital information with an Internet of Things; in contrast, there remains a lack of support to automate physical tasks that involve legacy static objects, e.g., adjusting a desk lamp’s angle for optimal brightness, turning on/off a manual faucet when washing dishes, sliding a window to maintain a preferred indoor temperature. Automating these simple physical tasks has the potential to improve people’s quality of life, which is particularly important for people with a disability or in situational impairment. We present Robiot—a design tool for generating mechanisms that can be attached to, motorized, and actuating legacy static objects to perform simple physical tasks. Users only need to take a short video manipulating an object to demonstrate an intended physical behavior. Robiot then extracts requisite parameters and automatically generates 3D models of the enabling actuation mechanisms by performing a scene and motion analysis of the 2D video in alignment with the object’s 3D model. In an hour-long design session, six participants used Robiot to actuate seven everyday objects, imbuing them with the robotic capability to automate various physical tasks.",
    "bibtex": "@inproceedings{10.1145/3332165.3347894,\nauthor = {Li, Jiahao and Kim, Jeeeun and Chen, Xiang 'Anthony'},\ntitle = {Robiot: A Design Tool for Actuating Everyday Objects with Automatically Generated 3D Printable Mechanisms},\nyear = {2019},\nisbn = {9781450368162},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3332165.3347894},\ndoi = {10.1145/3332165.3347894},\nabstract = {Users can now easily communicate digital information with an Internet of Things; in contrast, there remains a lack of support to automate physical tasks that involve legacy static objects, e.g. adjusting a desk lamp's angle for optimal brightness, turning on/off a manual faucet when washing dishes, sliding a window to maintain a preferred indoor temperature. Automating these simple physical tasks has the potential to improve people's quality of life, which is particularly important for people with a disability or in situational impairment.We present Robiot -- a design tool for generating mechanisms that can be attached to, motorized, and actuating legacy static objects to perform simple physical tasks. Users only need to take a short video manipulating an object to demonstrate an intended physical behavior. Robiot then extracts requisite parameters and automatically generates 3D models of the enabling actuation mechanisms by performing a scene and motion analysis of the 2D video in alignment with the object's 3D model. In an hour-long design session, six participants used Robiot to actuate seven everyday objects, imbuing them with the robotic capability to automate various physical tasks.},\nbooktitle = {Proceedings of the 32nd Annual ACM Symposium on User Interface Software and Technology},\npages = {673–685},\nnumpages = {13},\nkeywords = {actuation, design tool, everyday objects, generative design},\nlocation = {New Orleans, LA, USA},\nseries = {UIST '19}\n}",
    "acmref": "Jiahao Li, Jeeeun Kim, and Xiang 'Anthony' Chen. 2019. Robiot: A Design Tool for Actuating Everyday Objects with Automatically Generated 3D Printable Mechanisms. In <i>Proceedings of the 32nd Annual ACM Symposium on User Interface Software and Technology</i> (<i>UIST '19</i>). Association for Computing Machinery, New York, NY, USA, 673–685. DOI:https://doi.org/10.1145/3332165.3347894"
  },
  {
    "id": 9,
    "title": "3D Pen + 3D Printer: Exploring the Role of Human and Fabrication Machine in Creative Making",
    "abstract": "The emergence of a 3D pen brings 3D modeling from a screenbased computer-aided design (CAD) system and 3D printing to direct and rapid crafting by 3D doodling. However, 3D doodling remains challenging, requiring craft skills to rapidly express an idea, which is critical in creative making. We explore a new process of 3D modeling using 3D pen + 3D printer. Our pilot study shows that users need support to reduce the number of non-creative tasks to explore a wide design strategy. With the opportunity to invent a new 3D modeling process that needs to incorporate both a pen and printer, we propose techniques and a system that empower users to print while doodling to focus on creative exploration. Our user study shows that users can create diverse 3D models using a pen and printer. We discuss the roles of the human and fabrication machine for the future of fabrication.",
    "bibtex": "@inproceedings{10.1145/3290605.3300525,\nauthor = {Takahashi, Haruki and Kim, Jeeeun},\ntitle = {3D Pen + 3D Printer: Exploring the Role of Humans and Fabrication Machines in Creative Making},\nyear = {2019},\nisbn = {9781450359702},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3290605.3300525},\ndoi = {10.1145/3290605.3300525},\nabstract = {The emergence of a 3D pen brings 3D modeling from a screen-based computer-aided design (CAD) system and 3D printing to direct and rapid crafting by 3D doodling. However, 3D doodling remains challenging, requiring craft skills to rapidly express an idea, which is critical in creative making. We explore a new process of 3D modeling using 3D pen + 3D printer. Our pilot study shows that users need support to reduce the number of non-creative tasks to explore a wide design strategy. With the opportunity to invent a new 3D modeling process that needs to incorporate both a pen and printer, we propose techniques and a system that empower users to print while doodling to focus on creative exploration. Our user study shows that users can create diverse 3D models using a pen and printer. We discuss the roles of the human and fabrication machine for the future of fabrication.},\nbooktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},\npages = {1–12},\nnumpages = {12},\nkeywords = {creativity, 3d printer, digital fabrication, 3d pen},\nlocation = {Glasgow, Scotland Uk},\nseries = {CHI '19}\n}",
    "acmref": "Haruki Takahashi and Jeeeun Kim. 2019. 3D Pen + 3D Printer: Exploring the Role of Humans and Fabrication Machines in Creative Making. In <i>Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems</i> (<i>CHI '19</i>). Association for Computing Machinery, New York, NY, USA, Paper 295, 1–12. DOI:https://doi.org/10.1145/3290605.3300525"
  },
  {
    "id": 8,
    "title": "Mechamagnets: Designing and Fabricating Haptic and Functional Physical Inputs with Embedded Magnets",
    "abstract": "We present Mechamagnets, a technique for facilitating the design and fabrication of haptic and functional inputs for physical interfaces. This technique consists of a set of 3D printed spatial constraints which facilitate different physical movements, as well as unpowered haptic profiles created by embedding static magnets in 3D printed parts. We propose the Mechamagnets taxonomy to map the design space of this technique for designers and makers. Furthermore, we leverage the use of magnets by instrumenting these objects with linear Hall effect sensors to create functional digital inputs. We showcase Mechamagnets with a series of novel physical interfaces made with this technique.",
    "bibtex": "@inproceedings{10.1145/3294109.3295622,\nauthor = {Zheng, Clement and Kim, Jeeeun and Leithinger, Daniel and Gross, Mark D. and Do, Ellen Yi-Luen},\ntitle = {Mechamagnets: Designing and Fabricating Haptic and Functional Physical Inputs with Embedded Magnets},\nyear = {2019},\nisbn = {9781450361965},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3294109.3295622},\ndoi = {10.1145/3294109.3295622},\nabstract = {We present Mechamagnets, a technique for facilitating the design and fabrication of haptic and functional inputs for physical interfaces. This technique consists of a set of 3D printed spatial constraints which facilitate different physical movements, as well as unpowered haptic profiles created by embedding static magnets in 3D printed parts. We propose the Mechamagnets taxonomy to map the design space of this technique for designers and makers. Furthermore, we leverage the use of magnets by instrumenting these objects with linear Hall effect sensors to create functional digital inputs. We showcase Mechamagnets with a series of novel physical interfaces made with this technique.},\nbooktitle = {Proceedings of the Thirteenth International Conference on Tangible, Embedded, and Embodied Interaction},\npages = {325–334},\nnumpages = {10},\nkeywords = {3d printing, magnets, fabrication, haptics, prototyping},\nlocation = {Tempe, Arizona, USA},\nseries = {TEI '19}\n}",
    "acmref": "Clement Zheng, Jeeeun Kim, Daniel Leithinger, Mark D. Gross, and Ellen Yi-Luen Do. 2019. Mechamagnets: Designing and Fabricating Haptic and Functional Physical Inputs with Embedded Magnets. In <i>Proceedings of the Thirteenth International Conference on Tangible, Embedded, and Embodied Interaction</i> (<i>TEI '19</i>). Association for Computing Machinery, New York, NY, USA, 325–334. DOI:https://doi.org/10.1145/3294109.3295622"
  },
  {
    "id": 7,
    "title": "Compositional 3D Printing: Expanding & Supporting Workflows Towards Compositional 3D Printing",
    "abstract": "We present Compositional 3D Printing, recasting the 3D printer as a tool for expression that responds to real-time design decisions, analogous to composing a piece of music using a mixer. Our paradigm supports a wide range of inputs and interactions for designers, to be used in the moment; not only before printing, but anytime during production. We propose the design space of this digital fabrication paradigm, and outline methods and technical details with which researchers and practitioners can expand this space.",
    "bibtex": "@inproceedings{10.1145/3213512.3213518,\nauthor = {Kim, Jeeeun and Zheng, Clement and Takahashi, Haruki and Gross, Mark D and Ashbrook, Daniel and Yeh, Tom},\ntitle = {Compositional 3D Printing: Expanding &amp; Supporting Workflows towards Continuous Fabrication},\nyear = {2018},\nisbn = {9781450358545},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3213512.3213518},\ndoi = {10.1145/3213512.3213518},\nabstract = {We present Compositional 3D Printing, recasting the 3D printer as a tool for expression that responds to real-time design decisions, analogous to composing a piece of music using a mixer. Our paradigm supports a wide range of inputs and interactions for designers, to be used in the moment; not only before printing, but anytime during production. We propose the design space of this digital fabrication paradigm, and outline methods and technical details with which researchers and practitioners can expand this space.},\nbooktitle = {Proceedings of the 2nd ACM Symposium on Computational Fabrication},\narticleno = {5},\nnumpages = {10},\nkeywords = {3D printing, personal fabrication, creativity support},\nlocation = {Cambridge, Massachusetts},\nseries = {SCF '18}\n}",
    "acmref": "Jeeeun Kim, Clement Zheng, Haruki Takahashi, Mark D Gross, Daniel Ashbrook, and Tom Yeh. 2018. Compositional 3D printing: expanding &amp; supporting workflows towards continuous fabrication. In <i>Proceedings of the 2nd ACM Symposium on Computational Fabrication</i> (<i>SCF '18</i>). Association for Computing Machinery, New York, NY, USA, Article 5, 1–10. DOI:https://doi.org/10.1145/3213512.3213518"
  },
  {
    "id": 6,
    "title": "CraftML: 3D Modeling is Web Programming",
    "abstract": "We explore web programming as a new paradigm for programmatic 3D modeling. Most existing approaches subscribe to the imperative programming paradigm. While useful, there exists a gulf of evaluation between procedural steps and the intended structure. We present CraftML, a language providing a declarative syntax where the code is the structure. CraftML offers a rich set of programming features familiar to web developers of all skill levels, such as tags, hyperlinks, document object model, cascade style sheet, JQuery, string interpolation, template engine, data injection, and scalable vector graphics. We develop an online IDE to support CraftML development, with features such as live preview, search, module import, and parameterization. Using examples and case studies, we demonstrate that CraftML offers a low floor for beginners to make simple designs, a high ceiling for experts to build complex computational models, and wide walls to support many application domains such as education, data physicalization, tactile graphics, assistive devices, and mechanical components.",
    "bibtex": "@inproceedings{10.1145/3173574.3174101,\nauthor = {Yeh, Tom and Kim, Jeeeun},\ntitle = {CraftML: 3D Modeling is Web Programming},\nyear = {2018},\nisbn = {9781450356206},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3173574.3174101},\ndoi = {10.1145/3173574.3174101},\nabstract = {We explore web programming as a new paradigm for programmatic 3D modeling. Most existing approaches subscribe to the imperative programming paradigm. While useful, there exists a gulf of evaluation between procedural steps and the intended structure. We present CraftML, a language providing a declarative syntax where the code is the structure. CraftML offers a rich set of programming features familiar to web developers of all skill levels, such as tags, hyperlinks, document object model, cascade style sheet, JQuery, string interpolation, template engine, data injection, and scalable vector graphics. We develop an online IDE to support CraftML development, with features such as live preview, search, module import, and parameterization. Using examples and case studies, we demonstrate that CraftML offers a low floor for beginners to make simple designs, a high ceiling for experts to build complex computational models, and wide walls to support many application domains such as education, data physicalization, tactile graphics, assistive devices, and mechanical components.},\nbooktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},\npages = {1–12},\nnumpages = {12},\nkeywords = {programming, creativity support, fabrication, 3d printing, 3d modeling},\nlocation = {Montreal QC, Canada},\nseries = {CHI '18}\n}",
    "acmref": "Tom Yeh and Jeeeun Kim. 2018. CraftML: 3D Modeling is Web Programming. In <i>Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems</i> (<i>CHI '18</i>). Association for Computing Machinery, New York, NY, USA, Paper 527, 1–12. DOI:https://doi.org/10.1145/3173574.3174101"
  },
  {
    "id": 5,
    "title": "Understanding Uncertainty in Measurement and Accommodating its Impact in 3D Modeling and Printing",
    "abstract": "The growing accessibility of 3D printing to everyday users has led to rapid adoption, sharing of 3D models on sites such as thingiverse.com, and visions of a future in which customization is a norm and 3D printing can solve a variety of real world problems. However, in practice, creating models is difficult and many end users simply print models created by others. In this article, we explore a specific area of model design that is a challenge for end users – measurement. When a model must conform to a specific real world goal once printed, it is important that that goal is precisely specified. We demonstrate that measurement errors are a significant (yet often overlooked) challenge for end users through a systematic study of the sources and types of measurement errors. We argue for a new design principle—accommodating measurement error—that designers as well as novice modelers should to use at design time. We offer two strategies—buffer insertion and replacement of minimal parts—to help designers, as well as novice modelers, to build models that are robust to measurement error. We argue that these strategies can reduce the need for and costs of iteration and demonstrate their use in a series of printed objects.",
    "bibtex": "@inproceedings{10.1145/3064663.3064690,\nauthor = {Kim, Jeeeun and Guo, Anhong and Yeh, Tom and Hudson, Scott E. and Mankoff, Jennifer},\ntitle = {Understanding Uncertainty in Measurement and Accommodating Its Impact in 3D Modeling and Printing},\nyear = {2017},\nisbn = {9781450349222},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3064663.3064690},\ndoi = {10.1145/3064663.3064690},\nabstract = {The growing accessibility of 3D printing to everyday users has led to the rapid adoption, sharing of 3D models on sites such as thingiverse.com, and visions of a future in which customization is a norm and 3D printing can solve a variety of real-world problems. However, in practice, creating models is difficult and many end users simply print models created by others. In this paper, we explore a specific area of model design that is a challenge for end users' measurement. When a model must conform to a specific real world goal once printed, it is important that that goal is precisely specified. We demonstrate that measurement errors are a significant (yet often overlooked) challenge for end users through a systematic study of the sources and types of measurement errors. We argue for a new design principle--accommodating measurement error--that designers, as well as novice modelers, should to use at design time. We offer two strategies--buffer insertion and replacement of minimal parts--to help designers, as well as novice modelers, to build models that are robust to measurement error. We argue that these strategies can reduce the need for and costs of iteration and demonstrate their use in a series of printed objects.},\nbooktitle = {Proceedings of the 2017 Conference on Designing Interactive Systems},\npages = {1067–1078},\nnumpages = {12},\nkeywords = {personal fabrication, 3D printing, measurement, uncertainty},\nlocation = {Edinburgh, United Kingdom},\nseries = {DIS '17}\n}",
    "acmref": "Jeeeun Kim, Anhong Guo, Tom Yeh, Scott E. Hudson, and Jennifer Mankoff. 2017. Understanding Uncertainty in Measurement and Accommodating its Impact in 3D Modeling and Printing. In <i>Proceedings of the 2017 Conference on Designing Interactive Systems</i> (<i>DIS '17</i>). Association for Computing Machinery, New York, NY, USA, 1067–1078. DOI:https://doi.org/10.1145/3064663.3064690"
  },
  {
    "id": 4,
    "title": "Machines as Co-Designers: A Fiction on the Future of Human-Fabrication Machine Interaction",
    "abstract": "While current fabrication technologies have led to a wealth of techniques to create physical artifacts of virtual designs, they require unidirectional and constraining interaction workflows. Instead of acting as intelligent agents that support human’s natural tendencies to iteratively refine ideas and experiment, today’s fabrication machines function as output devices. In this work, we argue that fabrication machines and tools should be thought of as live collaborators to aid in-situ creativity, adapting physical dynamics come from unique materiality and/or machine specific parameters. Through a series of design narratives, we explore Human-FabMachine Interaction (HFI), a novel viewpoint from which to reflect on the importance of (i) interleaved design thinking and refinement during fabrication, (ii) enriched methods of interaction with fabrication machines regardless of skill level, and (iii) concurrent human and machine interaction.",
    "bibtex": "@inproceedings{10.1145/3027063.3052763,\nauthor = {Kim, Jeeeun and Takahashi, Haruki and Miyashita, Homei and Annett, Michelle and Yeh, Tom},\ntitle = {Machines as Co-Designers: A Fiction on the Future of Human-Fabrication Machine Interaction},\nyear = {2017},\nisbn = {9781450346566},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3027063.3052763},\ndoi = {10.1145/3027063.3052763},\nabstract = {While current fabrication technologies have led to a wealth of techniques to create physical artifacts of virtual designs, they require unidirectional and constraining interaction workflows. Instead of acting as intelligent agents that support human's natural tendencies to iteratively refine ideas and experiment, today's fabrication machines function as output devices. In this work, we argue that fabrication machines and tools should be thought of as live collaborators to aid in-situ creativity, adapting physical dynamics come from unique materiality and/or machine specific parameters. Through a series of design narratives, we explore Human-FabMachine Interaction (HFI), a novel viewpoint from which to reflect on the importance of (i) interleaved design thinking and refinement during fabrication, (ii) enriched methods of interaction with fabrication machines regardless of skill level, and (iii) concurrent human and machine interaction.},\nbooktitle = {Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems},\npages = {790–805},\nnumpages = {16},\nkeywords = {emerging design, creativity support, human-fabmachine interaction, concurrent collaboration},\nlocation = {Denver, Colorado, USA},\nseries = {CHI EA '17}\n}",
    "acmref": "Jeeeun Kim, Haruki Takahashi, Homei Miyashita, Michelle Annett, and Tom Yeh. 2017. Machines as Co-Designers: A Fiction on the Future of Human-Fabrication Machine Interaction. In <i>Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems</i> (<i>CHI EA '17</i>). Association for Computing Machinery, New York, NY, USA, 790–805. DOI:https://doi.org/10.1145/3027063.3052763"
  },
  {
    "id": 3,
    "title": "Facade: Auto-generating Tactile Interfaces to Appliances",
    "abstract": "Common appliances have shifted toward flat interface panels, making them inaccessible to blind people. Although blind people can label appliances with Braille stickers, doing so generally requires sighted assistance to identify the original functions and apply the labels. We introduce Facade—a crowdsourced fabrication pipeline to help blind people independently make physical interfaces accessible by adding a 3D printed augmentation of tactile buttons overlaying the original panel. Facade users capture a photo of the appliance with a readily available fiducial marker (a dollar bill) for recovering size information. This image is sent to multiple crowd workers, who work in parallel to quickly label and describe elements of the interface. Facade then generates a 3D model for a layer of tactile and pressable buttons that fits over the original controls. Finally, a home 3D printer or commercial service fabricates the layer, which is then aligned and attached to the interface by the blind person. We demonstrate the viability of Facade in a study with 11 blind participants.",
    "bibtex": "@inproceedings{10.1145/2982142.2982187,\nauthor = {Guo, Anhong and Kim, Jeeeun and Chen, Xiang 'Anthony' and Yeh, Tom and Hudson, Scott E. and Mankoff, Jennifer and Bigham, Jeffrey P.},\ntitle = {Facade: Auto-Generating Tactile Interfaces to Appliances},\nyear = {2016},\nisbn = {9781450341240},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/2982142.2982187},\ndoi = {10.1145/2982142.2982187},\nabstract = {Digital keypads have proliferated on common appliances, from microwaves and refrigerators to printers and remote controls. For blind people, such interfaces are inaccessible. We conducted a formative study with 6 blind people which demonstrated a need for custom designs for tactile labels without dependence on sighted assistance. To address this need, we introduce Facade - a crowdsourced fabrication pipeline to make physical interfaces accessible by adding a 3D printed augmentation of tactile buttons overlaying the original panel. Blind users capture a photo of an inaccessible interface with a standard marker for absolute measurements using perspective transformation. Then this image is sent to multiple crowd workers, who work in parallel to quickly label and describe elements of the interface. These labels are then used to generate 3D models for a layer of tactile and pressable buttons that fits over the original controls. Users can customize the shape and labels of the buttons using a web interface. Finally, a consumer-grade 3D printer fabricates the layer, which is then attached to the interface using adhesives. Such fabricated overlay is an inexpensive ($10) and more general solution to making physical interfaces accessible.},\nbooktitle = {Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility},\npages = {315–316},\nnumpages = {2},\nkeywords = {accessibility, blind users, crowdsourcing, personal fabrication},\nlocation = {Reno, Nevada, USA},\nseries = {ASSETS '16}\n}",
    "acmref": "Anhong Guo, Jeeeun Kim, Xiang 'Anthony' Chen, Tom Yeh, Scott E. Hudson, Jennifer Mankoff, and Jeffrey P. Bigham. 2016. Facade: Auto-generating Tactile Interfaces to Appliances. In <i>Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility</i> (<i>ASSETS '16</i>). Association for Computing Machinery, New York, NY, USA, 315–316. DOI:https://doi.org/10.1145/2982142.2982187"
  },
  {
    "id": 2,
    "title": "Reprise: A Design Tool for Specifying, Generating, and Customizing 3D Printable Adaptations on Everyday Objects",
    "abstract": "Everyday tools and objects often need to be customized for an unplanned use or adapted for specific user, such as adding a bigger pull to a zipper or a larger grip for a pen. The advent of low-cost 3D printing offers the possibility to rapidly construct a wide range of such adaptations. However, while 3D printers are now affordable enough for even home use, the tools needed to design custom adaptations normally require skills that are beyond users with limited 3D modeling experience. In this paper, we describe Reprise–a design tool for specifying, generating, customizing and fitting adaptations onto existing household objects. Reprise allows users to express at a high level what type of action is applied to an object. Based on this high level specification, Reprise automatically generates adaptations. Users can use simple sliders to customize the adaptations to better suit their particular needs and preferences, such as increasing the tightness for gripping, enhancing torque for rotation, or making a larger base for stability. Finally, Reprise provides a toolkit of fastening methods and support structures for fitting the adaptations onto existing objects. To validate our approach, we used Reprise to replicate 15 existing adaptation examples, each of which represents a specific category in a design space distilled from an analysis of over 3000 cases found in the literature and online communities. We believe this work would benefit makers and designers for prototyping lifehacking solutions and assistive technologies.",
    "bibtex": "@inproceedings{10.1145/2984511.2984512,\nauthor = {Chen, Xiang 'Anthony' and Kim, Jeeeun and Mankoff, Jennifer and Grossman, Tovi and Coros, Stelian and Hudson, Scott E.},\ntitle = {Reprise: A Design Tool for Specifying, Generating, and Customizing 3D Printable Adaptations on Everyday Objects},\nyear = {2016},\nisbn = {9781450341899},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/2984511.2984512},\ndoi = {10.1145/2984511.2984512},\nabstract = {Everyday tools and objects often need to be customized for an unplanned use or adapted for specific user, such as adding a bigger pull to a zipper or a larger grip for a pen. The advent of low-cost 3D printing offers the possibility to rapidly construct a wide range of such adaptations. However, while 3D printers are now affordable enough for even home use, the tools needed to design custom adaptations normally require skills that are beyond users with limited 3D modeling experience.In this paper, we describe Reprise--a design tool for specifying, generating, customizing and fitting adaptations onto existing household objects. Reprise allows users to express at a high level what type of action is applied to an object. Based on this high level specification, Reprise automatically generates adaptations. Users can use simple sliders to customize the adaptations to better suit their particular needs and preferences, such as increasing the tightness for gripping, enhancing torque for rotation, or making a larger base for stability. Finally, Reprise provides a toolkit of fastening methods and support structures for fitting the adaptations onto existing objects.To validate our approach, we used Reprise to replicate 15 existing adaptation examples, each of which represents a specific category in a design space distilled from an analysis of over 3000 cases found in the literature and online communities. We believe this work would benefit makers and designers for prototyping lifehacking solutions and assistive technologies.},\nbooktitle = {Proceedings of the 29th Annual Symposium on User Interface Software and Technology},\npages = {29–39},\nnumpages = {11},\nkeywords = {adaptation, design tool, 3d printing, everyday objects},\nlocation = {Tokyo, Japan},\nseries = {UIST '16}\n}",
    "acmref": "Xiang 'Anthony' Chen, Jeeeun Kim, Jennifer Mankoff, Tovi Grossman, Stelian Coros, and Scott E. Hudson. 2016. Reprise: A Design Tool for Specifying, Generating, and Customizing 3D Printable Adaptations on Everyday Objects. In <i>Proceedings of the 29th Annual Symposium on User Interface Software and Technology</i> (<i>UIST '16</i>). Association for Computing Machinery, New York, NY, USA, 29–39. DOI:https://doi.org/10.1145/2984511.2984512"
  },
  {
    "id": 1,
    "title": "Toward 3D-Printed Movable Tactile Pictures for Children with Visual Impairments",
    "abstract": "Many children's books contain movable pictures with elements that can be physically opened, closed, pushed, pulled, spun, flipped, or swung. But these tangible, interactive reading experiences are inaccessible to children with visual impairments. This paper presents a set of 3D-printable models designed as building blocks for creating movable tactile pictures that can be touched, moved, and understood by children with visual impairments. Examples of these models are canvases, connectors, hinges, spinners, sliders, lifts, walls, and cutouts. They can be used to compose movable tactile pictures to convey a range of spatial concepts, such as in/out, up/down, and high/low. The design and development of these models were informed by three formative studies including 1) a survey on popular moving mechanisms in children's books and 3D-printed parts to implement them, 2) two workshops on the process creating movable tactile pictures by hand (e.g., Lego, Play-Doh), and 3) creation of wood-based prototypes and an informal testing on sighted preschoolers. Also, we propose a design language based on XML and CSS for specifying the content and structure of a movable tactile picture. Given a specification, our system can generate a 3D-printable model. We evaluate our approach by 1) transcribing six children's books, and 2) conducting six interviews on domain experts including four teachers for the visually impaired, one blind adult, two publishers at the National Braille Press, a renowned tactile artist, and a librarian.",
    "bibtex": "@inbook{10.1145/2702123.2702144,\nauthor = {Kim, Jeeeun and Yeh, Tom},\ntitle = {Toward 3D-Printed Movable Tactile Pictures for Children with Visual Impairments},\nyear = {2015},\nisbn = {9781450331456},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/2702123.2702144},\nabstract = {Many children's books contain movable pictures with elements that can be physically opened, closed, pushed, pulled, spun, flipped, or swung. But these tangible, interactive reading experiences are inaccessible to children with visual impairments. This paper presents a set of 3D-printable models designed as building blocks for creating movable tactile pictures that can be touched, moved, and understood by children with visual impairments. Examples of these models are canvases, connectors, hinges, spinners, sliders, lifts, walls, and cutouts. They can be used to compose movable tactile pictures to convey a range of spatial concepts, such as in/out, up/down, and high/low. The design and development of these models were informed by three formative studies including 1) a survey on popular moving mechanisms in children's books and 3D-printed parts to implement them, 2) two workshops on the process creating movable tactile pictures by hand (e.g., Lego, Play-Doh), and 3) creation of wood-based prototypes and an informal testing on sighted preschoolers. Also, we propose a design language based on XML and CSS for specifying the content and structure of a movable tactile picture. Given a specification, our system can generate a 3D-printable model. We evaluate our approach by 1) transcribing six children's books, and 2) conducting six interviews on domain experts including four teachers for the visually impaired, one blind adult, two publishers at the National Braille Press, a renowned tactile artist, and a librarian.},\nbooktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},\npages = {2815–2824},\nnumpages = {10}\n}",
    "acmref": "Jeeeun Kim and Tom Yeh. 2015. Toward 3D-Printed Movable Tactile Pictures for Children with Visual Impairments. <i>Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems</i>. Association for Computing Machinery, New York, NY, USA, 2815–2824. DOI:https://doi.org/10.1145/2702123.2702144"
  },
  {
    "id": 0,
    "title": "Seen Music: Ambient Music Data Visualization for Children with Hearing Impairments",
    "abstract": "In this paper, we propose a prototype of music visualization system that captures and records the music component into digital data form, and then displays the data in visual form for children with hearing impairments. The analog sound data of music played physically is scaled into a binary matrix and scalar values that is then used as data structures for transcribing the output. We designed a system that detects tune and speed from a physical violin, and demonstrated three tangible music visualizations that children see in their daily lives, employing a flowerpot, plants and a picture of frame. We describe how the data captured from physical musical instruments can be seen through these objects, and suggest future possibilities for interactive sound visualization in music education for children with hearing impairments.",
    "bibtex": "@inproceedings{10.1145/2771839.2771870,\nauthor = {Kim, Jeeeun and Ananthanarayan, Swamy and Yeh, Tom},\ntitle = {Seen Music: Ambient Music Data Visualization for Children with Hearing Impairments},\nyear = {2015},\nisbn = {9781450335904},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/2771839.2771870},\ndoi = {10.1145/2771839.2771870},\nabstract = {In this paper, we propose a prototype of music visualization system that captures and records the music component into digital data form, and then displays the data in visual form for children with hearing impairments. The analog sound data of music played physically is scaled into a binary matrix and scalar values that is then used as data structures for transcribing the output. We designed a system that detects tune and speed from a physical violin, and demonstrated three tangible music visualizations that children see in their daily lives, employing a flowerpot, plants and a picture of frame. We describe how the data captured from physical musical instruments can be seen through these objects, and suggest future possibilities for interactive sound visualization in music education for children with hearing impairments.},\nbooktitle = {Proceedings of the 14th International Conference on Interaction Design and Children},\npages = {426–429},\nnumpages = {4},\nkeywords = {music education, assistive technology, music visualization},\nlocation = {Boston, Massachusetts},\nseries = {IDC '15}\n}",
    "acmref": "Jeeeun Kim, Swamy Ananthanarayan, and Tom Yeh. 2015. Seen music: ambient music data visualization for children with hearing impairments. In <i>Proceedings of the 14th International Conference on Interaction Design and Children</i> (<i>IDC '15</i>). Association for Computing Machinery, New York, NY, USA, 426–429. DOI:https://doi.org/10.1145/2771839.2771870"
  }
]